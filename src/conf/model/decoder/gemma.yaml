model_dir: "gemma"
quantization: True
embedding_size: 2048
Lora: True
lora_r: 16
lora_alpha: 32
lora_dropout: 0.1
lora_task_type: "CAUSAL_LM"
lora_bias: "none"
prompt: "user\nYou are a helpful AI assistant for recognizing the input video in English.Input:"
top_p: 0.9
top_k: 10
temperature: 0.9
max_new_tokens: 50